大型架构及配置
DAY01 ansible
DevOps
    DevOps（Development和Operations的组合词）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。
    它是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。
    它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作.
一.ansible
    使用时 千万要小心  rsync rm 这种都是危险操作
    1.1简介
        ansible是it自动化和DevOps软件 基于python开发 批量部署 批量运行命令
        ansible可以实现:
        -自动化部署app
        -自动化管理配置项目
        -自动化持续交互
        -自动化云服务管理

    1.2ansible 特性
         模块化设计,调运特定的模块完成特定任务
         基于python
         -paramiko
         -PyYAML
         -jinja2
         基于模块支持支持JSON 标准输出格式,可以采用任何编程语言重写
         部署简单
         主从模式工作
         自定义模块
         支持playbook
         易用使用
         支持多层部署
         支持异构it环境
    1.3 为什么选择ansible
        特点:
            社区活跃度
            学习成本
            使用成本
            编码语言
            性能
            使用广发
        优点:
            只要支持ssh和python
            无客户端
            ansible功能强大,模块丰富
            上手容易,门槛低
            二次开发容易
            活跃度高
    1.4 工作流程


            host1           cmd1
            host2           cmd2
            host3           cmd3
            ...             ...

            hostx           cmdx

        每台host 会遍历 命令集合,我们就是让一批机器执行一批命令

        ansible 执行流程

            读取配置
            抓起全量机器&分组列表
            使用host-pattern过滤机器列表
            根据参数确定执行模块和配置
            runner执行返回
            输出,结束


    1.5 安装
        软件依赖关系

            管理主机
                python 2.6 /2.7以上
                ansible需要一下模块
                    -paramiko
                    -PyYAML
                    -jinja2
                    -httplib2
                    -six


            被管理主机
                ansible 默认通过ssh协议管理
                被管理机器要开启ssh服务,允许ansible主机登录
                管理节点需要python2.5以上
                被管理节点开启selinux,需要安装 libselinux-python


        准备 6 台机器 1.40-1.45
        安装ansible
            yum 安装
                拷贝软件包到
                跟新索引文件 createrepo
                配置yum
            安装
                ansible管理主机上
                yum -y install ansible

                vim /etc/ansible/ansible.cfg
                    行取消注释
                    14 inventory      = /etc/ansible/hosts //主机集合
                    61 host_key_checking = False //不检查配置文件
    1.6主机定义与分组
        安装ansible后
            ########################### 记住啊######################
            ansible配置文件顺序查找
            -先检测ansible_config变量定义的配置文件
            -其次检测当前目录下的./ansible.cfg
            -再检查当前用户家目录下~/ansible.cfg文件
            -最后检查/etc/ansible/ansible.cfg文件
            /etc/ansible/ansible.cfg 是ansiblemore配置文件路径
            ansible.cfg 配置文件
                -inventory 定义托管主机地址配置文件路径
            ########################################################
            定义主机格式
                /etc/ansible/hosts 配置文件 位置
                [组名]
                主机名称/ip 其他参数
                vim /etc/ansible/hosts
                    添加
                    [web]
                    web[1:2]  //范围指定也可以向下面一样写
                    [db]
                    db[1:2]
                    [other]   //
                    cache
    1.7 ansible 命令

        ansible 主机集合 -m 模块 -a 模块参宿
            -主机集合 主机名/分组名 , 分割
            -m 模块名称 默认command模块
            -a / -args 模块参数
            -i inventory 文件路径/ 可执行脚本
            -k 使用交互式登录密码
            -e定义变量
            -v 显示详细信息

            显示可执行主机
            ansible web,db --list-hosts
            批量检测主机
            ansible web -m ping -k
            列出所有的可执行主机
            ansible all  --list-hosts

            部署免密码登录

            ssh-keygen -t rsa -b 2048 -N'' -f /root/.ssh/key
            for i in 41 42 43 44 45
            > do ssh-copy-id -i key.pub root@192.168.1.$i
            > done
            -i 指定 公钥文件
            再次检测
            ansible web -m ping

        inventory 扩展参数
            -ansible_ssh_port
                -ssh端口号: 若不是默认端口通过这个变量设置
                /etc/ansible/hosts
                [web]
                web1 ansible_ssh_port=22
            -ansible_ssh_user
                -默认的ssh用户名

            -ansible_ssh_pass
                -ssh密码 建议使用--ask-pass/ ssh秘钥
            -ansible_ssh_private_key_file
                -ssh使用的私钥文件,使用于多个秘钥,并不想使用ssh代理

            vars变量定义,用于用户组名后面
                [all:vars]   //all表示全部组,
                ansible_ssh_private_key_file="/root/.ssh/key"
            children 子组定义,引用其他组名称
                [app:children]
                web    //其他组名.非主机名
                db

            自定义配置文件
                有多少人就可以有多少配置文件,分组只限制与本文件(用户)
                创建 文件夹 myansible
                创建配置文件ansible.cfg
                    sed -n "14p;61p" /etc/ansible/ansible.cfg
                    [defaults]  //配置文件分组名称
                    inventory = myhost      //14 行
                    host_key_checking = False  //61 行

                配置主机文件
                    [app]
                    web1
                    db1
                    cache
                    [app1]
                    web1
                测试 ansible app -m ping

            动态主机
                无限可能
                    ansible inventory 包含静态和动态的inventory,静态的inventory
                    指在文件/etc/ansible/hosts中指定的主机和组
                    动态inventory指通过外部的脚本获取主机列表,按照要求格式返回给ansible命令

                json
                    Javascriptobjectnotation,Javascript对象表示法,一种基于文本独立于语言的轻量级数据交换格式



    1.8ansible 模块

        ansible-doc和ping模块

            ansible-doc
                -模块的手册相当于shell的man,  (非常重要,ansible必备)
                ansible-doc -l          //列出所有模块
                ansible-doc modulename   //查看帮助
            ping 模块
                测试网络连通性,ping模块没有参数,测试的ssh链接是否成功
                ansible host-pattern -m ping


            command模块
                ansible是并发执行
                默认模块,远程执行命令
                    ansible host-pattern -m command -a 'args'
                    查看机器负载
                    ansible all -m command -a 'free -mh'
                    查看当前时间日期
                    ansible all -m command -a 'date +%F_%T'
                command模块注意事项
                    -该模块通过-a 跟上需要执行的命令可以直接执行,若命令中有如下字符则不能执行
                    "<" ">" "|" "&"
                    -command模块不能解析系统变量
                    -该模块不起动shell 直接在ssh进程中执行,所有使用到shell的命令都会失败
                    - 下面命令会失败
                    -ansible all -m command -a 'ps aux |grep ssh'
            shell 模块
                -shell 模块用法基本和command一样,区别是shell模块通过/bin/sh 执行命令,可以执行任意命令
                -不能执行交互命令 如 vim top

                ansible all -m shell -a "echo ${HOSTNAME}"  //本地bash解析
                    db2 | SUCCESS | rc=0 >>
                    ansible
                ansible all -m shell -a 'echo ${HOSTNAME}'  //远程bash解析
                    db1 | SUCCESS | rc=0 >>
                    DB1

                ansible all -m shell -a 'echo \${HOSTNAME}'
                    web1 | SUCCESS | rc=0 >>
                    ${HOSTNAME}

                testfile 文件在哪里
                    ansible cache -m shell -a 'cd /tmp'
                    ansible cache -m shell -a 'touch testfile'

                问题解析
                    变量解析
                        -ansible 执行 命令是二次解析
                        -第一次在本机解析,第二次在执行机器解析
                        -需要第二次解析的变量要转义(\)
                    文件在哪里
                        -文件子用户家目录
                        -ansible是使用ssh多次链接执行
                        -链接退出后之前状态就全部失效
                        -解决方法使用chdir 代替cd

                给web1,db2 添加用户nb ,修改nb密码为123
                    ansible web1,db2 -m shell -a 'useradd nb && echo 123 |passwd --stdin nb'

            script 模块
                通过该模块可以执行脚本
               -在本地写脚本,然后使用script模块批量执行
               -注意:该脚本包含但不限于shell脚本,只要指定sha-bang解释器的脚本都可以
                ansible cache -m script -a 'useradd.sh'
                    vim useradd
                        #!/bin/bash
                        id nb
                        if [ $? != 0 ];then
                        useradd wk
                        echo 456 | passwd --stdin wk
                        fi

            yum模块
                -通过该模块使用yum包管理器
                -name 要进行操作的软件包名字
                -state 动作 (installed ,removed)
                -installed 安装
                -removed  删除

                ansible db -m yum -a 'name=mariadb-server state=installed'

            service模块
                -name 必选项,服务名
                -enabled 是否开机启动 yes/no
                -sleep 执行restarted,会在stop和start之间睡几秒
                -state 对应当前服务执行启动 停止 重启 重新加载
                -started stopped restarted reloaded

                ansible db -m service -a 'name=mariadb state=started enabled=yes'

            copy模块
                -复制文件远程主机
                -src 复制本地文件到远程主机,绝对路径和相对路径都可以,
                路径为目录时会递归复制.若路径以'/'结尾,则复制目录里面的内容,
                若不以'/'结尾,则复制包含目录在内的整个内容类似rsync
                -dest 必选项.远程主机的绝对路径,如源文件是一个目录,那路径必须是目录
                -backup 覆盖前先备份源文件,备份文件包含时间信息 选项:yes/no
                -force 若目标主机包含文件,单内容不同,若设置为yes,则墙纸覆盖,若设置为no,则只有当目标主机目标位置不存在该文件才会复制,默认为yes
                -复制文件
                    ansible all -m copy -a 'src=my.cnf dest=/etc/my.cnf'

                -复制目录
                    ansible all -m copy -a 'src=/etc/yum.repos.d/ dest=/etc/yum.repos.d/'



            lineinfile 模块
                -一个类似与sed的一种行编辑替换模块
                -path  目标文件
                -regexp 正则表达式,要修改的行
                -line 最终的修改结果
                -例如修改my.cnf,中 bin-log
                ansible db -m lineinfile -a 'path="/etc/my.cnf" regexp="^binlog-format" line="binlog-format = row"'

            replace 模块
                -一个类似与sed的一种行编辑替换模块
                -path  目标文件
                -regexp 正则表达式,要修改的行
                -replace 最终的修改结果
                -例如替换指定字符 row-->mixed
                ansible db -m replace -a 'path="/etc/my.cnf" regexp="row" replace="mixed"'


            setup 模块
                -主要用来获取主机信息,playbooks里经常会用的另一个参数gather_facts与该模块相关,
                setup模块下经常用的是filter参数
                -filter 过滤所需的信息

                ansible cache -m setup -a 'filter=ansible_distribution'


DAY02
    PLAYBOOK
    一.playbook 基础
        1.1ansible 七中武器
            第一种  (必须掌握)
                ansible 命令,用于执行零时性工作
            第二种  (必须掌握)
                ansible-doc 是ansible模块的文档说明,类似于man命令
            第三种 (必须掌握)
                ansible-console是ansible为用户提供的交互的工具
                用户可以使用ansible-console虚拟出来的终端上想使用shell一样使用ansible内置命令
            第四种
                ansible-galaxy从github上下载管理Roles的一款工具与python的pip一样
            第五种 (必须掌握)
                ansible-playbook 是日常使用中频率最高的命令,工作机制:通过读取先编写好的PLAYBOOK文件实现批量管理,可以理解为按照一定的条件组成的ansible任务集
            第六种
                ansible-vault主要用户配置文件加密,如编写的PLAYBOOK文件中包含敏感信息,用他可以加密/解密文件
            第七种
                ansible-pull
                ansible 有两种工作模式 pull/push 默认pull.pull和push的工作机制刚好相反
                适用场景: 有大量机器需要配置,即便适用高并发线程也需要花费很多时间
                通常配置大批量机器先适用,灵活性稍有欠缺,但效率几乎可以无限提升.

        1.2json简介
        json是什么
                json是JavaScript对象表示法,一种基于文本独立于语言的轻量级数据交换格式
                分隔符限于   ' ()  [] {} : , 这几种
                独立于语言,与使用什么编程语言无关
                eg:
                [1,2,3,4]
                {key:value}
        json特性
            json是纯文本
            json具有人类可读性
            json具有层级别结构 --可以互相嵌套
            json可通过Javascript进行解析
        json语法
            -数据在名称/值对中
            -数据由"," 分隔
            -{} 保存对象
            -[] 保存数组
        json 数组的书写格式  名称/值对
            名称/值对 包含字段名称(在""中),后面写一个:,然后是值
            "key":"value"
        json语法规则-数组
           { "key":["k1":"v1",["1","2","3","4"],"k2":["k3":"v3"]]
            }
            犇哥: 牛犇
            讲师:[牛犇,王凯,丁丁,静静,xx]
            讲师:[
                {姓名:牛犇,爱好:大锤},
                {姓名:王凯,爱好:吃香蕉},
                {姓名:丁丁,爱好:写书},
                {姓名:静静,爱好:养猫},
                {姓名:xx,爱好:开车}
            ]

        1.3jinja2介绍
            jinja2 是什么
                jinja2

            jinja2 模板基本语法
                -模板的表达式都是包含在分隔符"{{ }}"内的
                -控制语句都是包含在分隔符"{% %}" 内的
                -模板支持注释,都是包含在分隔符"{# #}" 内,支持块注释
                -调用变量
                    {{username}}
                -计算
                    {{2+3}}
                -判断
                     {{1 in [1,2,3]}}
            jinja2控制语句

                if 判断
                    {% if name == '诗仙' %}
                        dc
                    {% elif name == '诗圣' %}
                        ch
                    {% elif name == '诗魔' %}
                          bj
                    {% else %}
                        lh
                    {% endif %}

                    if
                    elif
                    else
                    endif

                for 循环
                    {% if name == .... %}
                        ... ...
                    {% elif name == '于谦' %}
                       {% for method in [抽烟,喝酒,烫头] %}
                        {{do method}}
                       {% endfor %}
                       ... ...

                    {% endif %}

                    for i in xx
                    do i
                    endfor


        1.4YAML简介
            YAML是什么
                高可读,用来表达数据数列的格式
                YAML已有多种编程语言的支持
            YAML基础语法
                YAML的结构通过空格来展示
                数组使用 - 来表示
                键值对使用 : 来表示
                YAML使用一个固定的缩进风格表示数据层级结构关系
                一般每个缩进级别由两个以上空格组成(千万不能使用table,用来就语法错误)
                #表示注释

                注意: 不要使用table ,缩进是初学者易出错的地方
                      同一层级必须对齐
            YAML的键值
                采用: 分隔
                :后面必须有一个空格
                YAML键值对例子

                key: value /
                key:
                  value
            YAML数组表示
                使用一个短横杠加一个空格
                json
                    讲师:[牛犇,王凯,丁丁,静静,xx]
                YAML
                   讲师:
                     - 牛犇
                     - 王凯
                     - 丁丁
                     - 静静
                     - xx
                json
                    讲师:[
                        {姓名:牛犇,爱好:大锤},
                        {姓名:王凯,爱好:吃香蕉},
                        {姓名:丁丁,爱好:写书},
                        {姓名:静静,爱好:养猫},
                        {姓名:xx,爱好:开车}
                    ]

                YAML

                    讲师:
                      -
                        姓名: 牛犇    ## 每层级 俩个空格分隔,"key:"与"value"间是有一个空格
                        爱好: 大锤
                      -
                        姓名: 王凯
                        爱好: 吃香蕉
                      -
                        姓名: 丁丁
                        爱好: 写书
                      -
                        姓名: 静静
                        爱好: 养猫
                      -
                        姓名: xx
                        爱好: 开车

    二.PLAYBOOK
        什么是PLAYBOOK
            ansible用于配置,部署和管理托管主机剧本,通过PLAYBOOK的详细描述,执行一系列的tasks

        为什么要使用PLAYBOOK
            执行简单的任务,使用ad-hoc

        PLAYBOOK语法基础
            PLAYBOOK语法
                PLAYBOOK由YAML编写,
                #表示注释
                同一列表元素保持缩进
                PLAYBOOK由一个/多个play组成
                play中hosts,variables,roles,tasks等对象表示方法都是键值以':' 分隔
                YAML开始 为---
            playbook构成
                hosts: 定义要执行PLAYBOOK的远程主机组
                vars: 定义PLAYBOOK运行时需要使用的变量
                tasks: 定义将要在远程主机上执行的任务列表
                handlers: 定义tasks执行完成后需要调用的任务
            PLAYBOOK执行结果
                绿色 成功
                红色 失败
                黄色 系统状态改变


            eg1:
                ---
                - hosts: all
                  remote_user: root
                  tasks:
                    - ping:
        变量
            eg2:
                ---
                - hosts: web
                  remote_user: root
                  vars:
                    username: l4
                  tasks:
                    - name: "create user "
                      user:
                        name: "{{username}}"
                        group: users
                    - name: "change_passwd"
                      shell: echo 123 |passwd --stdin "{{username}}"

            eg3:  变量过滤器
                ---
                - hosts: web
                  remote_user: root
                  vars:
                    username: w5
                  tasks:
                    - name: "create user "
                      user:
                        name: "{{username}}"
                        group: users
                        password: "{{'123'|password_hash('sha512')}}"


            eg4:参数传递
                ansible-playbook user.01.yml -e "{username:  ll}"
                ---
                - hosts: web
                  remote_user: root
                  tasks:
                    - name: "create user "
                      user:
                        name: "{{username}}"
                        group: users
                        password: "{{'123'|password_hash('sha512')}}"

            eg5: 参数传递
                ansible-playbook user.01.yml -e @username.yml

                vim username.yml
                ---
                username:
                  nb
                vim  user.01.yml
                ---
                - hosts: web
                  remote_user: root
                  tasks:
                    - name: "create user "
                      user:
                        name: "{{username}}"
                        group: users
                        password: "{{'123'|password_hash('sha512')}}"
            eg6: 安装httpd

                ---
                - hosts: web
                  remote_user: root
                  tasks:
                    - yum:
                        name: httpd
                        state: latest
                    - lineinfile:
                        path: /etc/httpd/conf/httpd.conf
                        regexp: '^Listen 80'
                        insertafter: '^#Listen '
                        line: 'Listen 8080'
                    - copy:
                        src: /root/index.html
                        dest: /var/www/html/index.html
                        owner: apache
                        group: apache
                        mode: 0644
                    - service:
                        name: httpd
                        state: started
                        enabled: yes

                vim index.html
                    html1
        erro模块
            忽略错误继续执行,
            ignore_errors: True
                True  忽略错误继续执行
                False 默认 遇到错误停止

                eg: 在web 上的创建 /tmp/cache 并 修改配置文件重新加载配置文件
                    ---
                    - hosts: web
                      remote_user: root
                      tasks:
                        - shell: mkdir /tmp/cache
                          ignore_errors: True
                        - copy:
                            src: /root/httpd.conf
                            dest: /etc/httpd/conf/httpd.conf
                            owner: apache
                            group: apache
                            mode: 0644
                        - service:
                            name: httpd
                            state: restarted
                            enabled: yes

        tag 标识
            调用 : ansible-playbook apacher_tags.yml -t syncconf
                ---
                - hosts: web
                  remote_user: root
                  tasks:
                #    - shell: mkdir /tmp/cache
                #      ignore_errors: True
                    - copy:
                        src: /root/httpd.conf
                        dest: /etc/httpd/conf/httpd.conf
                        owner: apache
                        group: apache
                        mode: 0644
                      tags: syncconf  ##与copy同级
                    - name: restart apache
                      service:
                        name: httpd
                        state: restarted
                        enabled: yes
        when 条件触发
            需要满足特定条件后出发某一项操作,或在特定条件下执行某个行为

            tasks:
              - name: somecommand
                  command: somecommand
                  when: expr
            eg:
                ---
                - name: Install vim
                  hosts: all
                  tasks:
                    - name: Install vim yum
                      yum: name=vim-enhanced state=installed
                      when: ansible_os_family == "RedHat"
                    - name: Install vim apt
                      apt: name=vim state=installed
                      when: ansible_os_family == "Debian"
        with_itmes  playbooks 标准循环

            通过{{item}} 获取每次迭代的值
            创建多个用户
            ---
            - hosts: web
              remote_user: root
              tasks:
                - name: add users
                  user: group=wheel |password="{{'123456'|password_hash('sha512')}} name={{item}}"
                  with_items:["nd","dd","plj","lx"]

            with_items 进阶

                为不同用户定义不同组
                ---
                - hosts: db


                  tasks:
                    - name: adduser "{{item.name}}"
                      user:
                        name: "{{item.name}}"
                        group: "{{item.group}}"
                        password: "{{item.pwd|password_hash('sha512')}}"
                      with_items:
                        -
                          name: nb
                          group: nobody
                          pwd: "123456"
                        -
                          name: wk
                          group: users
                          pwd: "654321"
                        -
                          name: dd
                          group: adm
                          pwd: nginx
                        -
                          name: jj
                          group: mysql
                          pwd: 123qqq...A
                        -
                          name: xx
                          group: root
                          pwd: a




        register  保存前一个命令的结果
            有时候我们需要前面一个命令的执行结果来判断是否要执行后面的操作,
            我们需要register模块来保存前一个命令的返回状态,在后面调用
            - command: test command
              register: result
            - command: run command
              when: result
            变量注册进阶
                -针对运行命令结果返回值做判定
                -当系统负载超过一定值做特殊处理

                vim dubug.yml
                ---
                - hosts: web
                  remote_user: root
                  tasks:
                    - shell: uptime | awk '{printf("%.2f",$(NF-2))}'
                      register: result      ####显示详细的错误信息
                    - service:
                        name: httpd
                        state: stopped
                      when: result.stdout|float > 0.7   #####result.stdout|float将输出字符转化为数值, 经过测试不转化为float也可以执行成功









        handlers 触发器
            ansible-playbook apacher_change.yml
                ---
                - hosts: web
                  remote_user: root
                  tasks:
                #    - shell: mkdir /tmp/cache
                #      ignore_errors: True
                    - copy:
                        src: /root/httpd.conf
                        dest: /etc/httpd/conf/httpd.conf
                        owner: apache
                        group: apache
                        mode: 0644
                #      tags: syncconf
                      notify:
                        - restart apache
                  handlers:  ###与tasks 同级 ,执行玩tasks后 才会执行 handler
                    - name: restart apache
                      service:
                        name: httpd
                        state: restarted
                        enabled: yes







        include and roles 调用PLAYBOOK文件
            include
                由于PLAYBOOK文件会随着项目越来越大,PLAYBOOK也会越来越复杂,我们可以把
                play tasks handler 分别写入不同文件 通过include指令包含进来

                tasks:
                  -include: tasks/setup.yml
                  -include: tasks/user.yml user=plj  ##user.yml 中可以通过{{user}} 来使用变量

                handler:
                  -include: handler/handlers.yml
            roles
                roles 像是一个加强版的include,他可以引入一个项目的文件和目录
                一般所需的目录层级有
                 -vars: 变量
                 -tasks: 任务层
                 -handler:出发层
                 -file: 文件
                 -template: 模板
                 -default: 默认,优先级最低

                 eg: 加入有一个play包含一个叫x的role则
                    ---
                    -hosts: host_group
                    roles:
                      -x
                 -x/tasks/main.yml
                 -x/vars/main.yml
                 -x/handler/main.yml
                 -x/.../main.yml
                 这些都会添加到这和play







        debug 模块
            检测语法 ansible-playbook --syntax-check test.yml

            运行测试 ansible-playbook -C test.yml
                由于测试和检测语法的问题可能 会检测失败,但是写的PLAYBOOK 并没有问题
            调用:ansible-playbook dubug.yml
            当一分钟之内的cpu使用率达到70%后就停止httpd服务,在报错时显示详细信息
            vim dubug.yml
            ---
            - hosts: web
              remote_user: root
              tasks:
                - shell: uptime | awk '{printf("%.2f",$(NF-2))}'
                  register: result      ####显示详细的错误信息
                - service:
                    name: httpd
                    state: stopped
                  when: result.stdout|float > 0.7   #####result.stdout|float将输出字符转化为数值, 经过测试不转化为float也可以执行成功
                - name: show debug info
                  debug: var=result

DAY03
    一.elk
        1.1 elk是什么
            elk 是一套日志监控解决方案 ,三个软件产品字母缩写,均为开源软件
            elasticsearch  日志检测和存储   (数据库)
            logstash       日志的收集和分析处理  (Java程序,处理log可视化-类似于php)
            kibana         负责日志的可视化  (web软件--类似nginx)

            虽然elk可zabbix都是监控软件但是,这是两个不同的监控方向,zabbix 监控服务,机器状态,elk监控日志


        1.2 elk能做什么
            -分布式日柱数据集中式查询和管理
            -系统监控,包含系统硬件和应用的各个组件的监控
            -故障排查
            -安全信息的事件管理
            --报表功能
        1.3 elasticsearch 特点
            非关系型数据库
            实时性
            分布式实时文档存储
            所有对象全是文档
            高可用 易于扩展 支持集群 分片和复制
            接口友好 支持json

            es 没有什么
            典型意义的事物
            面向文档的数据库
            没有授权和认证
        1.4 elasticsearch 相关概念

            node 装有es服务器节点
            cluster 有多个node组成集群
            document 一个可被搜索的基础信息单元     row       行
            index 拥有相似特征的文档集合           database
            type 一个索引中可定义一种/多种类型      table     表
            filed es最小单位 相当于数据的某一列     column    列
            shards 索引的分片,每一个分片就是shard
            replicas 索引的拷贝
            关系行
            DB--->database-->table-->rows-->columns

                                      行        列
            ES-->index-->types--> documents-->fields
                 索引     类型      文档          预


        1.5 安装

            准备 7台虚拟机
            配置 elk的 yum源
             createrepo .

            单台
            yum -y install  java-1.8.0-openjdk
            yum -y install elasticsearch
            vim +54 /etc/elasticsearch/elasticsearch.yml
            network.host: 0.0.0.0  //修改如下
            systemctl restart elasticsearch.service
            ss -antulp |grep 9200
            ss -antulp |grep 9300
            systemctl enable elasticsearch.service
            集群
            安装软件相同 只是修改的配置文件 有所不同
            vim /etc/hosts  //每台机器都要做
            192.168.1.51 es1
            192.168.1.52 es2
            192.168.1.53 es3
            192.168.1.54 es4
            192.168.1.55 es5
            192.168.1.56 kibana
            192.168.1.57 logstash
            192.168.1.58 Apache
            vim /etc/elasticsearch/elasticsearch.yml
            17 cluster.name: myelk        //配置集群名字
            23 node.name: es1        //当前主机名称,集群中node.name必须不同,与主机名一致,之前修改了hosts
            54 network.host: 0.0.0.0     // 0.0.0.0（监听所有地址）
            68 discovery.zen.ping.unicast.hosts: ["es1", "es2", "es3"]
            //声明集群里的主机成员有谁，不需要全部写进去,但是在启动其他机器的服务时这三台机器的服务必须先启动.
            集群中的其他机器在启动后会寻址这三台机器来确认集群
            systemctl restart elasticsearch.service
            启动没有 报错信息 若检查9300/9200 无端口 请检查 systemctl status elasticsearch.service 和  vim /var/log/messages 拍错
            访问测试 查看node 数量
            firefox http://192.168.1.51:9200/_cluster/health?pretty
                "number_of_nodes" : 5,

        安装插件
               27  cd /usr/share/elasticsearch/bin/
               28  ./plugin install ftp://192.168.1.254/elk/bigdesk-master.zip
               31  ./plugin install ftp://192.168.1.254/elk/elasticsearch-head-master.zip
               32  ./plugin list
               33  ./plugin install ftp://192.168.1.254/elk/elasticsearch-kopf-master.zip
               34  ./plugin list

        访问测试

            http://192.168.1.51:9200/_plugin/bigdesk/#nodes
            http://192.168.1.51:9200/_plugin/kopf/#!/cluster
            http://192.168.1.51:9200/_plugin/head/
                索引名称     nsd
                分片数        5    将数据分成5份存在服务器
                副本数量       2   每台服务器报错一份源数据两份备份

                最多坏两台服务器



        补充知识
            http协议

                GET POST HEAD

                OPTIONS PUT DELETE TRACE和CONNECT
            ES 常用
                PUT         增
                DELETE      删
                POST        改
                GET         查

            命令 curl
                   -A 修改请求 agent -A
                   -X 设置请求方法
                   -i 显示返回头信息

                   curl -A Safari/537.36 -Li http://www.jkgaoyuan.ml |head -10

                      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                                     Dload  Upload   Total   Spent    Left  Speed
                    100  1104    0  1104    0     0   1319      0 --:--:-- --:--:-- --:--:--  1318HTTP/1.1 200 OK
                    Server: nginx/1.16.0
                    Date: Tue, 16 Jul 2019 06:45:32 GMT
                    Content-Type: text/html; charset=UTF-8
                    Transfer-Encoding: chunked
                    Connection: keep-alive
                    X-Powered-By: PHP/5.6.40

                   curl -A Safari/537.36 -Li -X PUT http://118.144.89.240/info.php

                    HTTP/1.1 200 OK
                    Server: nginx
                    Date: Tue, 16 Jul 2019 06:48:24 GMT
                    Content-Type: text/html; charset=UTF-8
                    Transfer-Encoding: chunked
                    Connection: keep-alive
                    Set-Cookie: PHPSESSID=f13e90b9a3b7fcc167e5e69c88445099; path=/
                    Expires: Thu, 19 Nov 1981 08:52:00 GMT
                    Cache-Control: no-store, no-cache, must-revalidate
                    Pragma: no-cache

                    <pre>
                    [ REQUEST_METHOD] ==> PUT
                    [    REMOTE_ADDR] ==> 223.255.15.21
                    [HTTP_USER_AGENT] ==> Safari/537.36
                    [   HTTP_REFERER] ==>



            RESTful API 调用
                显示 所有cat目录
                curl  http://192.168.1.51:9200/_cat/
                curl  http://192.168.1.51:9200/_cat/recovery
                显示 详细的 health信息 ?v 表示显示详细信息
                curl  http://192.168.1.51:9200/_cat/health?v

                通过命令行创建索引
                [root@es1 ~]# curl -XPUT http://192.168.1.51:9200/tedu -d '{
                >   "settings":{
                >     "index" :{
                >       number_of_shards: 5,
                >       number_of_replicas: 1
                >               }
                >               }
                > }'
                这里的ip地址填写从服务器/主服务器都可以
                插入数据
                                                    索引   类型   域
                curl -XPUT http://192.168.1.51:9200/tedu/teacher/3 -d '{
                "name": "ff",
                "age": "35",
                "gender": "man",
                "like": "chaoyan"
                }'

                修改数据
                    -XPOST  _update  {"doc": {}} 为固定格式
                curl -XPOST http://192.168.1.51:9200/tedu/teacher/4/_update -d '{"doc": {"gender":"wmen"}}'

                查询
                curl -XGET http://192.168.1.51:9200/tedu/teacher/6?putty
                删除
                    就是不能删除类型
                删除字段
                curl -XDELETE http://192.168.1.51:9200/tedu/teacher/5?putty
                删除索引
                curl -XDELETE http://192.168.1.51:9200/tedu/
                删库
                curl -XDELETE http://192.168.1.51:9200/*

                批量导入数据

                lftp 192.168.1.254
                cd elk/
                get logs.jsonl.gz
                logs.jsonl.gz
                shakespeare.json.gz

                gzip -d *.gz

                curl -XPOST 'http://192.168.1.51:9200/_bulk' --data-binary @logs.jsonl
                curl -XPOST 'http://192.168.1.51:9200/_bulk' --data-binary @shakespeare.json
                curl -XPOST 'http://192.168.1.51:9200/x/xx/_bulk/' --data-binary @accounts.json

                accounts.json
                {"index":{"_id":"1"}}^M
                shakespeare.json
                {"index":{"_index":"shakespeare","_type":"act","_id":0}}

                这是表中必须包含的,但是account.json 缺少了 索引和 类型,我们应在导入数据时补上索引和类型
                索引 类型 字段



        1.6kibana
            安装 配置yum,使用 es1 使用的 yum源

                yum -y install kibana
            修改配置文件
                 vim /opt/kibana/config/kibana.yml


                  2 server.port: 5601

                  5 server.host: "0.0.0.0"

                  15 elasticsearch.url: "http://es1:9200"


                  23 kibana.index: ".kibana"

                  26 kibana.defaultAppId: "discover"

                  53   elasticsearch.pingTimeout: 1500
                  57   elasticsearch.requestTimeout: 30000
                  64   elasticsearch.startupTimeout: 5000



                  systemctl restart kibana.service
                  http://192.168.1.56:5601/status

                  状态为green则为正常

                  http://192.168.1.56:5601/

                    discover

                    kibana选择日志

                      支持通配符
                      选择logstash-*
                      time-field  选择 @timestramp
                      create

                      选择时间范围  右上角
                      15.5.17  51.5.21
                      框选


                    visualiz

                    pie chart


        1.7 logstash

            安装
                 yum -y install java-1.8.0-openjdk
                 yum -y install logstash

                 安装位置
                    /opt/logstash/

                    默认没有 配置文件

                 编写配置文件
                    默认包含三部分
                        input{}  输入
                        filter{} 处理
                        output{} 输出
                    vim /opt/logstash/logstash.conf

                    input{
                            stdin{}
                    }
                    filter{ }
                    output{
                            stdout{}
                    }

                 启动
                    -f 指定配置文件位置
                    /opt/logstash/bin/logstash -f logstash.conf

                 查看logstash 已经安装的插件
                    /opt/logstash/bin/logstash-plugin list

                 由于logstash的插件众多,可以访问下面两个 网站寻找帮助
                    https://github.com/logstash-plugins
                    https://www.elastic.co/guide/en/logstash/current/index.html   // INPUT filter OUTPUT 这三项


                 配置file插件
                    vim /opt/logstash/logstash.conf


                    input{
                            file{
                            start_position => "beginning"    // 开始读取log文件的位置,这个参数受到下面文件的影响,并且优先级高于 position
                            sincedb_path => "/var/lib/logstash/sinedb-access"    // 将指针文件定向到 /var/lib/logstash/sinedb-access, 该文件决定了服务启动后,读取log文件位置,该文件默认在 /root .sincedb_xxx
                            path => ["/tmp/a.log","/var/tmp/b.log"]
                            type => "a.log"                  //标记

                            }
                    }

                    filter{ }
                    output{
                            stdout{ codec => "rubydebug"}
                    }


DAY04
    大型架构的配置及其技术

    一.大数据
        定义:无法再一定时间范围内用常规软件工具进行捕捉管理和处理的数据集合

            从海量数据中快速获取有价值的信息.

            大规模并行处理数据库,数据挖掘,分布式文件系统,/数据库,云计算和可扩展的存储系统

        特点: 数量(vloume)  速度(velocity) 种类(variety) 价值(value) 真实性(veracity)

    二.Hadoop
        定义: 分析和处理海量数据的软件平台
              开源 Java分支
              分布式基础架构

              高可靠 高扩展 高效性 高容错 低成本
        最先有Google 发布的三篇论文  产生 GFS MapReduce BigTable 组成
        之后有Yahoo 依照论文用Java 进行实现
            GFS------> HDFS
            MapReduce------>  MapReduce
            BigTable------> Hbase


        1.1Hadoop 常用组件

            HDFS      hadoop分布式文件系统  核心
            mapreduce 分布式计算框架        核心
            Yarn      集群资源管理系统      核心
            Zookeeper 分布式协作服务
            Hbase     分布式列存数据库
            Hive      基于hadoop的数据仓库
            Sqoop     数据同步工具

        1.2 hdfs 角色及概念
            1.2.1 hdfs结构
                client
                    切分文件
                    访问hdfs
                    与namenode交互,获取文件位置信息
                    与datanode交互,读取和写入数据
                datanode
                    数据存储节点,存储实际数据
                    汇报存储信息给namenode
                namenode
                    master节点,管理hdfs的名称空间和数据块映射信息(该文件名fsimage什么数据存储位置),
                    配置副本策略(数据存储几份),处理所有客户请求,(管理数据具体存储位置)

                secondary namenode
                    定期合并fsimage 和fsedits(数据变更日志,记录数据何处变化), 推送给namenode
                    紧急情况下,辅助恢复namenode
                    但是secondary namenode 非namenode 热备份
                block
                    每块128m大小
                    每块多副本

            1.2.2 mapreduce

                    由Java实现的分布式计算框架
                    jobtracker  分解任务
                        master节点
                        管理所有的作业/任务监控/错误处理
                        将任务分解,分配给tasktracker
                    tasktracker 执行任务

                    map task
                        分析记录每条数据记录,传递给用户编写的map()并执行,将输出结果写入本地磁盘
                        -若map-only 作业,直接写入 hdfs
                    reducer task
                        从map task的执行结果中,远程读取输入数据,对数据进行排序,将数据安装分组,传递给用户编写的reduce函数执行


            1.2.3 yarn
                    核心: 将jobtracker 和task tracker 分离,由下面几大组件构成
                         -resourcemanager 一个全局的资源管理节点
                         -nodemanager   每个节点(RM)代理
                         -applicationmaster 表示每个应用
                         -每一个applicationmaster有多个container在nodemanager上运行


                    resourcemanager
                       处理客户端请求
                       启动/监控applicationmaster
                       监控nodemanager
                       资源分配与调度

                    nodemanager

                        单个节点的资源管理
                        处理来自resourcemanager
                        处理来自applicationmaster
                    container

                        对任务运行环境的抽象,封装了cpu 内存
                        对维度资源及环境变量,启动命令的任务运行相关的信息
                    applicationmaster

                        数据切分
                        为应用申请资源,并分配内部任务
                        任务监控与容错
                    client
                        用户与yarn的交互客户端
                        提交应用程序,监控 应用程序状态,杀死应用

        1.3 hadoop
                模式

                    单机
                    伪分布式  测试开发
                    完全分布式  生产


                单机install Hadoop

                    安装Java环境
                    yum -y install java-1.8.0-openjdk-devel


                    tar -xf hadoop-2.7.7.tar.gz  -C

                    cp -r hadoop-2.7.7/ /usr/local/hadoop/

                    配置Java的运行环境
                    vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh

                    指定 Java安装路径
                    rpm -ql java-1.8.0-openjdk
                    export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre"
                    指定hadoop的配置文件 位置
                    export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"

                    cd /usr/local/hadoop
                    mkdir testinput

                    cp LICENSE.txt  NOTICE.txt README.txt testinput/
                    bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount testinput/ testoutput

                    wordcount 是内置的命令
                    wordcount 输入目录  输出目录(会自己创建)  我们只需要准备好输入目录中的内容就好

                    查看结果
                    cat testoutput/part-r-00000


                伪分布式

                    伪分布式的安装和完全分布式类似,区别在与所有的角色安装在一台机器上面,使用本地磁盘,一般生产环境都会使用完全分布式,伪分布式用来学习和测试

                    伪分布式配置和完全分布式配置类似

                hadoop配置文件及格式

                    xml文件配置格式
                    <property>
                        <name>关键词</name>
                        <value>变量</value>
                        <description>描述</description>
                    </property>


                搭建完全分布式

                    准备三台机器(两台node 一台namenode,算上上午的node1 一共四台) 配置/etc/hosts
                      ping通namenode
                      192.168.1.60 node1
                      192.168.1.61 node2
                      192.168.1.62 node3
                      192.168.1.63 namenode

                      java -version 验证java
                      jps 验证角色

                    确保 namenode 能面秘钥远程 node1-3 包括本机

                        vim /etc/ssh/ssh_config
                        Host *
                        GSSAPIAuthentication yes
                        StrictHostKeyChecking no
                                     加密长度 算法  不需要密码  文件名称
                        ssh-keygen -b 2048 -t rsa -N '' -f .ssh/id_rsa

                        ssh-copy-id root@node1
                        ssh-copy-id root@node2
                        ssh-copy-id root@node3
                        ssh-copy-id root@namenode


                    修改hdfsde配置文件

                        下面配置文件的参数可以在下面网站的左下角找到
                        http://hadoop.apache.org/docs/stable/

                        ##################
                        core-site.xml
                        #################
                        vim /usr/local/hadoop/etc/hadoop/core-site.xml

                                hadoop.tmp.dir  数据的根目录, 类似mysql /usr/lib/mysql
                            将<configuration>中添加如下

                            <configuration>

                                <property>
                                    <name>fs.defaultFS</name>
                                    <value>hdfs://namenode:9000</value>
                                </property>
                                <property>
                                    <name>hadoop.tmp.dir</name>
                                    <value>/var/hadoop</value>
                                </property>

                            </configuration>

                            ##############
                            hdfs-site.xml
                            #############

                            vim /usr/local/hadoop/etc/hadoop/core-site.xml
                                哪里启动 namenode
                                哪里启动 secondary namenode

                            <configuration>
                                <property>
                                    <name>dfs.namenode.http-address</name>
                                    <value>namenode:50070</value>
                                </property>
                                <property>
                                    <name>dfs.namenode.secondary.http-address</name>
                                    <value>namenode:50090</value>
                                </property>
                                <property>
                                    <name>dfs.replication</name>
                                    <value>3</value>
                                </property>
                            </configuration>

                            ###########
                            slaves
                            ###########
                                声明谁是datanode
                            vim /usr/local/hadoop/etc/hadoop/slaves

                            node1
                            node2
                            node3

                        同步配置

                          scp -r /usr/local/hadoop/ root@node2:/usr/local/hadoop/
                          scp -r /usr/local/hadoop/ root@node3:/usr/local/hadoop/
                          scp -r /usr/local/hadoop/ root@namenode3:/usr/local/hadoop/

                        在namenode上初始化并启动服务,检查集群状态

                            cd /usr/local/hadoop
                            ./bin/hdfs namenode -format    //初始化
                            ./sbin/start-dfs.sh            //启动服务
                            ./bin/hdfs dfsadmin -report    // 检查集群状态

                            ./sbin/stop-dfs.sh              //停止服务
                            ./sbin/stop-all.sh              //停止所有服务

                            jps 验证

                                23985 Jps
                                23747 SecondaryNameNode
                                23564 NameNode

                        日志位置
                            每台机器都有
                            /usr/local/hadoop/logs/

                        rsync -avXSH



                    修改 mapreduce 和 Yarn 的配置文件

                        ssh root@namenode
                        cd /usr/local/hadoop/etc/hadoop/
                        mv mapred-site.xml.template mapred-site.xml

                        vim mapred-site.xml

                        <configuration>
                        <property>
                            <name>mapreduce.framework.name</name>
                            <value>yarn</value>
                        </property>

                        </configuration>


                         vim yarn-site.xml

                        <configuration>

                        <!-- Site specific YARN configuration properties -->

                        <property>
                                <name>yarn.resourcemanager.hostname</name>
                                <value>namenode</value>
                        </property>
                        <property>
                                <name>yarn.nodemanager.aux-services</name>
                                <value>mapreduce_shuffle</value>
                        </property>
                        </configuration>

                    同步配置文件

                        for i in node{1..3};do rsync -avXSH /usr/local/hadoop/etc ${i}:/usr/local/hadoop/; done

                    启动
                        因为上面已经启动了dfs ,这里只需要启动yarn
                        /usr/local/hadoop/sbin/start-yarn.sh


                    检查
                        namenode
                        jps

                            23747 SecondaryNameNode
                            24248 ResourceManager
                            24507 Jps
                            23564 NameNode

                            namenode 主机
                            注意这里ip需要与你设定的ip一致
                        http://192.168.1.63:50070/        //--namenode web页面
                        http://192.168.1.63:50090/        //--secondory namenode web页面
                        http://192.168.1.60:50075/        //--datanode web页面（node1,node2,node3）
                        http://192.168.1.63:8088/        //--resourcemanager web页面
                        http://192.168.1.60:8042/        //--nodemanager web页面（node1,node2,node3）